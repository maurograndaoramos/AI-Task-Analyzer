# AI-Powered Task Assistant (Full-Stack)

This project is a full-stack AI-Powered Task Assistant application. It features a FastAPI backend that uses Crew AI for intelligent task analysis and a Next.js (React) frontend for user interaction. Users can create tasks, and an AI agent automatically analyzes these tasks to determine their category and priority.

## Project Overview

The application allows users to:

*   **Create Tasks:** Submit new tasks via a web interface, providing details like description, user story, and context.
*   **View Tasks:** See a list of all tasks and their details, including AI-assigned categories and priorities.
*   **AI-Powered Analysis:** A Crew AI agent (`TaskAnalyzerAgent`) on the backend processes task details to assign a category (e.g., "Bug Fix", "Feature Request") and a priority (e.g., "High", "Medium", "Low").
*   **API Backend:** A FastAPI application provides RESTful API endpoints for task management.
*   **Frontend Interface:** A Next.js application provides the user interface for interacting with the tasks.
*   **Database:** Tasks are stored in a SQLite database (configurable via `DATABASE_URL` for the backend).

## Features

*   **Full-Stack Application:** Next.js frontend and FastAPI backend.
*   **Intelligent Task Analysis:** Backend integration with Crew AI for automated task categorization and prioritization.
*   **RESTful API:** FastAPI backend for robust task management.
*   **Reactive Frontend:** User-friendly interface built with Next.js and React.
*   **Database Persistence:** SQLite database for storing task data.
*   **Containerized Deployment:** Docker and Docker Compose for both backend and frontend services.
*   **CI Pipeline:** Basic CI with GitHub Actions for backend linting and testing.

## Tech Stack

*   **Frontend:**
    *   Next.js
    *   React
    *   TypeScript
    *   Tailwind CSS
    *   Shadcn/ui (for UI components)
    *   `pnpm` (for package management)
*   **Backend:**
    *   FastAPI
    *   Python 3.11+
    *   Crew AI
    *   OpenAI (requires `GEMINI_API_KEY` for AI features)
*   **Database:** SQLite (using `databases` library for async backend access)
*   **Backend Testing:** Pytest, Pytest-Asyncio
*   **Backend Linting:** Ruff
*   **Containerization:** Docker, Docker Compose

## Project Structure

```
.
├── backend/                # Backend FastAPI application
│   ├── app/                # Main application code
│   │   ├── __init__.py
│   │   ├── main.py         # FastAPI application entry point
│   │   ├── agents/         # Crew AI agents
│   │   ├── api/            # API versioning and endpoints
│   │   ├── core/           # Core components like DB setup, config
│   │   └── services/       # Business logic services
│   ├── tests/              # Automated tests for backend
│   ├── .dockerignore       # Docker ignore for backend
│   ├── requirements.txt    # Python dependencies
│   └── ...                 # (other backend files like Dockerfile, pytest.ini)
├── frontend/               # Frontend Next.js application
│   ├── app/                # Next.js app router pages
│   ├── components/         # React components
│   ├── lib/                # Frontend libraries, context, api calls
│   ├── public/             # Static assets
│   ├── .gitignore          # Git ignore for frontend
│   ├── package.json
│   ├── pnpm-lock.yaml
│   ├── tsconfig.json
│   └── ...                 # (other frontend files like next.config.mjs)
├── .github/                # GitHub Actions workflows
│   └── workflows/
│       └── ci.yml
├── .env.example            # Example environment variables for backend
├── .gitignore              # Root .gitignore
├── Dockerfile              # Dockerfile for the backend API service (top-level for docker-compose context)
├── docker-compose.yml      # Docker Compose for running all services
├── Makefile                # Optional: for common commands
├── README.md               # This file
└── REPORT.md               # Project report
```
*Note: SQLite database files (e.g., `sql_app.db`, `test.db`) generated by the backend are included in `.gitignore` and will not be committed to the repository.*

## Setup and Installation

### Prerequisites

*   **Node.js** (v18.x or later recommended, for frontend)
*   **pnpm** (for frontend package management: `npm install -g pnpm`)
*   **Python** (3.11+ for backend)
*   **Docker and Docker Compose** (for containerized deployment of all services)
*   An **OpenAI API Key** (for AI features)

### Option 1: Running with Docker (Recommended for Full Application)

This method runs both the backend API and the frontend application in containers.

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd <project_directory_name>
    ```

2.  **Set up Backend Environment Variables:**
    Create a `.env` file in the project root (where `docker-compose.yml` is located) by copying `.env.example`:
    ```bash
    cp .env.example .env
    ```
    Edit the `.env` file and add your `GEMINI_API_KEY`:
    ```
    GEMINI_API_KEY="your_gemini_api_key_here"
    DATABASE_URL="sqlite:///./sql_app.db" # Default SQLite path for data persisted via Docker volume
    ```
    *The database file (`sql_app.db`) will be created automatically if it doesn't exist when the backend starts. It is configured in `docker-compose.yml` to persist on your host machine (e.g., in a `./backend_data/` directory or directly as `sql_app.db` depending on your `docker-compose.yml` volume setup).*

3.  **Build and Run with Docker Compose:**
    In the project root directory:
    ```bash
    docker-compose up --build
    ```
    *   The backend API will be available at `http://localhost:8000`.
    *   The frontend application will be available at `http://localhost:3000`.
    *   Backend API documentation (Swagger UI) can be found at `http://localhost:8000/docs`.

### Option 2: Local Development Setup (Running Backend and Frontend Separately)

#### A. Backend Setup (FastAPI)

1.  **Navigate to the backend directory:**
    ```bash
    cd backend
    ```
2.  **Create and activate a Python virtual environment:**
    ```bash
    python -m venv venv
    # On Windows: venv\Scripts\activate
    # On macOS/Linux: source venv/bin/activate
    ```
3.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Set up Backend Environment Variables:**
    Create a `.env` file in the `backend` directory by copying `../.env.example` (the one from the root):
    ```bash
    cp ../.env.example .env  # Or just `cp .env.example .env` if you also have one in `backend/`
    ```
    Edit this `backend/.env` file with your `GEMINI_API_KEY` and desired `DATABASE_URL` (e.g., `sqlite:///./sql_app.db`).
    *The database file will be created in the `backend` directory if it doesn't exist.*
5.  **Run the Backend Application:**
    From the `backend` directory:
    ```bash
    uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
    ```
    The API will be available at `http://localhost:8000`.

#### B. Frontend Setup (Next.js)

1.  **Navigate to the frontend directory (in a new terminal):**
    ```bash
    cd frontend
    ```
2.  **Install Node.js dependencies using pnpm:**
    ```bash
    pnpm install
    ```
3.  **(Optional) Frontend Environment Variables:**
    The frontend is configured to connect to the backend API at `http://localhost:8000/api/v1` by default (see `frontend/lib/api.ts`). If your backend API is running on a different URL during local development (e.g., if you changed the port), you can create a `frontend/.env.local` file with:
    ```
    NEXT_PUBLIC_API_URL=http://your_backend_api_base_url
    ```
    *Ensure `frontend/.env.local` is included in `frontend/.gitignore` (it is by default with `.env*`).*
4.  **Run the Frontend Development Server:**
    ```bash
    pnpm dev
    ```
    The frontend application will be available at `http://localhost:3000`.

## API Usage

The main API endpoint for tasks is `/api/v1/tasks/` (served by the backend at `http://localhost:8000/api/v1/tasks/`).
The frontend application interacts with these endpoints to create, view, and manage tasks. For direct API interaction, refer to the backend's Swagger documentation at `http://localhost:8000/docs`.

*   **`POST /api/v1/tasks/`**: Create a new task.
    *   Request Body (JSON):
        ```json
        {
          "description": "Implement user profile page",
          "user_story": "As a user, I want to see my profile information.",
          "context": "This is part of the V2 user features."
        }
        ```
    *   Response (JSON): The created task object, including AI-generated `category` and `priority`.

*   **`GET /api/v1/tasks/`**: Retrieve a list of all tasks.
    *   Supports `skip` and `limit` query parameters for pagination.

*   **`GET /api/v1/tasks/{task_id}`**: Retrieve a specific task by its ID.

## Running Backend Tests

Backend tests are run using Pytest.

1.  Navigate to the `backend` directory.
2.  Ensure your Python virtual environment is activated and development dependencies (like `pytest`) are installed.
3.  Set the `GEMINI_API_KEY` in your `backend/.env` file or as an environment variable if you want to run integration tests that make real AI calls (otherwise, they will be skipped).
4.  Run pytest from the `backend` directory:
    ```bash
    pytest
    ```

## CI Pipeline

A basic CI pipeline is set up using GitHub Actions (`.github/workflows/ci.yml`). It performs for the backend:
*   Linting with Ruff.
*   Unit and integration tests with Pytest.
The pipeline requires the `GEMINI_API_KEY` to be set as a secret in the GitHub repository settings for backend integration tests involving AI to run successfully.

## Future Enhancements (Potential)

*   Frontend testing setup (e.g., with Jest/React Testing Library).
*   More sophisticated AI agents for other task-related actions.
*   User authentication and authorization across frontend and backend.
*   Support for other databases (e.g., PostgreSQL).
*   Enhanced error handling and user feedback in the frontend.
*   Websocket support for real-time updates between frontend and backend.
